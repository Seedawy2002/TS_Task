{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9662597,"sourceType":"datasetVersion","datasetId":5903680}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setting Up","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import StandardScaler\nimport os\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:44.004289Z","iopub.execute_input":"2024-10-19T20:37:44.005159Z","iopub.status.idle":"2024-10-19T20:37:44.009781Z","shell.execute_reply.started":"2024-10-19T20:37:44.005116Z","shell.execute_reply":"2024-10-19T20:37:44.008867Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"## Saving (training-validation) files names","metadata":{}},{"cell_type":"code","source":"# Base path where the CSV files are stored in the Kaggle environment\nbase_path = '../input/train-splits/'\n\n# List all CSV files in the folder dynamically\nfile_names = [f for f in os.listdir(base_path) if f.endswith('.csv')]","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:44.364382Z","iopub.execute_input":"2024-10-19T20:37:44.364678Z","iopub.status.idle":"2024-10-19T20:37:44.370200Z","shell.execute_reply.started":"2024-10-19T20:37:44.364646Z","shell.execute_reply":"2024-10-19T20:37:44.369449Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"markdown","source":"## Needed functions for the pipeline","metadata":{}},{"cell_type":"code","source":"# Helper function to preprocess the dataset\ndef preprocess_data(df):\n    # Ensure 'timestamp' and 'value' columns exist\n    if 'timestamp' not in df.columns:\n        raise KeyError(\"'timestamp' column is missing from the input data\")\n    \n    if 'value' not in df.columns:\n        raise KeyError(\"'value' column is missing from the input data\")\n\n    # Convert 'timestamp' to datetime and set as index\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df.set_index('timestamp', inplace=True)\n    \n    # Apply forward fill first\n    df.ffill(inplace=True)\n\n    # Apply backfill to handle remaining NaNs at the start\n    df.bfill(inplace=True)\n    \n    # If NaNs persist, drop them if needed\n    df.dropna(inplace=True)\n    \n    # Feature Engineering: \n    # 1. Add lag features\n    df['lag_1'] = df['value'].shift(1)\n    df['lag_2'] = df['value'].shift(2)\n    df['lag_3'] = df['value'].shift(3)\n\n    # Backfill for initial NaNs in lag features\n    df[['lag_1', 'lag_2', 'lag_3']] = df[['lag_1', 'lag_2', 'lag_3']].bfill()\n\n    if 'anomaly' in df.columns:\n        # Forward fill the 'value' column only where 'anomaly' is 1\n        df.loc[df['anomaly'] == True, 'value'] = pd.NA  # Mark as NaN where anomaly is detected\n        df['value'] = df['value'].ffill()  # Forward fill to replace incorrect values\n        \n        # Drop the 'anomaly' column after making the changes\n        df = df.drop('anomaly', axis=1)\n    \n    # 2. Add Rate of Change (Derivatives)\n    df['rate_of_change'] = df['value'].diff()\n    df['rate_of_change_2'] = df['rate_of_change'].diff()\n\n    # Fill NaNs from differencing\n    df[['rate_of_change', 'rate_of_change_2']] = df[['rate_of_change', 'rate_of_change_2']].bfill()\n\n    # 3. Add Rolling Window Statistics (Moving Average, Std Dev, Min, Max)\n    df['rolling_mean_5'] = df['value'].rolling(window=5).mean()\n    df['rolling_std_5'] = df['value'].rolling(window=5).std()\n    df['rolling_min_5'] = df['value'].rolling(window=5).min()\n    df['rolling_max_5'] = df['value'].rolling(window=5).max()\n\n    # Fill NaNs from rolling windows\n    df[['rolling_mean_5', 'rolling_std_5', 'rolling_min_5', 'rolling_max_5']] = df[['rolling_mean_5', 'rolling_std_5', 'rolling_min_5', 'rolling_max_5']].bfill()\n\n    # 4. Add Exponential Moving Average (EMA)\n    df['ema_5'] = df['value'].ewm(span=5, adjust=False).mean()\n\n    # Fill NaNs from EMA\n    # Backfill for 'ema_5' column without inplace=True\n    df['ema_5'] = df['ema_5'].bfill()\n\n    # Apply forward fill first\n    df.ffill(inplace=True)\n    \n    # 5. Add Outlier Detection (Z-score)\n    df['z_score'] = (df['value'] - df['value'].mean()) / df['value'].std()\n    df['is_anomaly'] = (df['z_score'].abs() > 3).astype(int)  # Mark anomalies where Z-score exceeds threshold\n\n    # 6. Add Time-Based Features (Hour, Day, Month)\n    df['hour'] = df.index.hour\n    df['day_of_week'] = df.index.dayofweek\n    df['day_of_month'] = df.index.day\n    df['month'] = df.index.month\n\n    # 7. Add Cyclic Feature Encoding (Sin/Cos Transforms for Time)\n    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n\n    # If NaNs persist, drop them if needed\n    df.dropna(inplace=True)\n    \n    # Scaling the features\n    scaler = StandardScaler()\n    feature_columns = ['value', 'lag_1', 'lag_2', 'lag_3', \n                       'rate_of_change', 'rate_of_change_2', \n                       'rolling_mean_5', 'rolling_std_5', 'rolling_min_5', 'rolling_max_5', \n                       'ema_5', 'z_score', 'is_anomaly',\n                       'hour', 'day_of_week', 'day_of_month', 'month', \n                       'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos']\n\n    # Apply scaling only to the selected columns\n    df[feature_columns] = scaler.fit_transform(df[feature_columns])\n    #print(df)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:44.678458Z","iopub.execute_input":"2024-10-19T20:37:44.679072Z","iopub.status.idle":"2024-10-19T20:37:44.697478Z","shell.execute_reply.started":"2024-10-19T20:37:44.679037Z","shell.execute_reply":"2024-10-19T20:37:44.696634Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Summary:\n\n1. **Validating Columns:**  \n   Ensures the dataset has essential columns (`timestamp` for time ordering and `value` for the data to be analyzed).\n\n2. **Datetime Conversion and Indexing:**  \n   Converts `timestamp` to a datetime format and sets it as the index for efficient time series operations.\n\n3. **Handling Missing Data:**  \n   Uses forward and backward filling to ensure no gaps remain in the data, preserving continuity in the time series.\n\n4. **Lag Features:**  \n   Adds previous time step values (lag features) to capture temporal dependencies, providing the model with context about past behavior.\n\n5. **Anomaly Handling (Optional):**  \n   Replaces anomaly-affected values by forward filling to maintain data integrity and removes the `anomaly` column.\n\n6. **Rate of Change Features:**  \n   Calculates the rate of change (first and second derivatives) to identify trends, shifts, and acceleration in the data.\n\n7. **Rolling Statistics:**  \n   Adds rolling mean, standard deviation, min, and max to smooth the data and capture local patterns over time.\n\n8. **Exponential Moving Average (EMA):**  \n   Adds EMA to highlight recent trends by giving more weight to recent observations.\n\n9. **Outlier Detection (Z-Score):**  \n   Detects and flags extreme values (outliers) that could distort analysis by using a Z-score threshold.\n\n10. **Time-Based Features:**  \n   Adds hour, day, and month features to capture seasonal and cyclical patterns in the data.\n\n11. **Cyclic Feature Encoding:**  \n   Uses sin/cos transformations for cyclical features (like hours and days) to help models recognize periodic patterns.\n\n12. **Feature Scaling:**  \n   Standardizes features to ensure equal contribution during model training, preventing large-scale features from dominating.","metadata":{}},{"cell_type":"code","source":"# Function to calculate baseline MSE (predicting the mean value)\ndef calculate_baseline_mse(y_train, y_test):\n    baseline_pred = [y_train.mean()] * len(y_test)  # Predicting the mean for all test values\n    baseline_mse = mean_squared_error(y_test, baseline_pred)\n    return baseline_mse","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:44.971871Z","iopub.execute_input":"2024-10-19T20:37:44.972156Z","iopub.status.idle":"2024-10-19T20:37:44.976433Z","shell.execute_reply.started":"2024-10-19T20:37:44.972126Z","shell.execute_reply":"2024-10-19T20:37:44.975644Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"### Comments\n- MSE (model) tells how well model performs.\n- Baseline MSE tells how a naive model performs.\n- Comparing the two shows if model's complexity is justified and whether it's actually improving prediction accuracy.","metadata":{}},{"cell_type":"code","source":"# Function to save a trained model\ndef save_model(model, file_name):\n    # Save the model to disk\n    model_save_path = f\"saved_models/{file_name}.pkl\"\n    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n    joblib.dump(model, model_save_path)\n    print(f\"Model saved to {model_save_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:45.243972Z","iopub.execute_input":"2024-10-19T20:37:45.244710Z","iopub.status.idle":"2024-10-19T20:37:45.249105Z","shell.execute_reply.started":"2024-10-19T20:37:45.244676Z","shell.execute_reply":"2024-10-19T20:37:45.248209Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# Function to train and validate a model on a dataset and compare with baseline\ndef train_and_validate(df, file_name):\n    # Preprocess the data\n    df = preprocess_data(df)\n\n    # Split into features (X) and target (y)\n    X = df[['lag_1','lag_2','lag_3','rate_of_change', 'rate_of_change_2', \n           'rolling_mean_5', 'rolling_std_5', 'rolling_min_5', 'rolling_max_5', \n           'ema_5', 'z_score', 'is_anomaly',\n           'hour', 'day_of_week', 'day_of_month', 'month', \n           'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos']]\n    y = df['value']\n\n    # Time-based cross-validation (use TimeSeriesSplit)\n    tscv = TimeSeriesSplit(n_splits=5)\n\n    # Initialize model\n    model = RandomForestRegressor(n_estimators=100, random_state=42)\n\n    mse_scores = []\n    baseline_mse_scores = []\n\n    for train_index, test_index in tscv.split(X):\n        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\n        # Train the model\n        model.fit(X_train, y_train)\n\n        # Make predictions\n        y_pred = model.predict(X_test)\n\n        # Calculate MSE for model predictions\n        mse = mean_squared_error(y_test, y_pred)\n        mse_scores.append(mse)\n\n        # Calculate baseline MSE\n        baseline_mse = calculate_baseline_mse(y_train, y_test)\n        baseline_mse_scores.append(baseline_mse)\n\n        # Optionally, plot the predictions vs actual values\n        #plot_predictions(y_test, y_pred, title=f\"{file_name}: Model Predictions vs Actual\")\n\n    # Get the average MSE for the model\n    avg_mse = sum(mse_scores) / len(mse_scores)\n\n    # Get the average baseline MSE\n    avg_baseline_mse = sum(baseline_mse_scores) / len(baseline_mse_scores)\n\n    # Print comparison\n    #print(f\"Processed {file_name}, Model MSE: {avg_mse}, Baseline MSE: {avg_baseline_mse}\")\n    \n    # Save the model after training\n    save_model(model, file_name)\n\n    return avg_mse, avg_baseline_mse","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:45.574985Z","iopub.execute_input":"2024-10-19T20:37:45.575253Z","iopub.status.idle":"2024-10-19T20:37:45.584667Z","shell.execute_reply.started":"2024-10-19T20:37:45.575224Z","shell.execute_reply":"2024-10-19T20:37:45.583701Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"# Main function to apply pipeline to all datasets\ndef run_pipeline():\n    results = {}\n    \n    # Loop over each file in the folder\n    for file_name in file_names:\n        file_path = os.path.join(base_path, file_name)\n        \n        # Load the dataset\n        df = pd.read_csv(file_path)\n        \n        # Train and validate on the dataset, and get MSE values\n        model_mse, baseline_mse = train_and_validate(df, file_name.replace('.csv', ''))\n        \n        # Store results for both model MSE and baseline MSE\n        results[file_name] = {'Model MSE': model_mse, 'Baseline MSE': baseline_mse}\n        print(f\"Processed {file_name}, Model MSE: {model_mse}, Baseline MSE: {baseline_mse}\")\n    \n    return results","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:45.927824Z","iopub.execute_input":"2024-10-19T20:37:45.928576Z","iopub.status.idle":"2024-10-19T20:37:45.933754Z","shell.execute_reply.started":"2024-10-19T20:37:45.928543Z","shell.execute_reply":"2024-10-19T20:37:45.932937Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"## Running the pipeline to get and evaluate the models","metadata":{}},{"cell_type":"code","source":"# Run the pipeline\npipeline_results = run_pipeline()","metadata":{"execution":{"iopub.status.busy":"2024-10-19T20:37:48.441289Z","iopub.execute_input":"2024-10-19T20:37:48.442004Z","iopub.status.idle":"2024-10-19T20:59:17.375627Z","shell.execute_reply.started":"2024-10-19T20:37:48.441966Z","shell.execute_reply":"2024-10-19T20:59:17.374729Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Model saved to saved_models/train_506.pkl\nProcessed train_506.csv, Model MSE: 0.006408909825334078, Baseline MSE: 1.0051548484945483\nModel saved to saved_models/train_446.pkl\nProcessed train_446.csv, Model MSE: 0.041065716469621025, Baseline MSE: 1.0765738218045644\nModel saved to saved_models/train_352.pkl\nProcessed train_352.csv, Model MSE: 0.002542640537321867, Baseline MSE: 1.1003476859849317\nModel saved to saved_models/train_29.pkl\nProcessed train_29.csv, Model MSE: 0.0003044780617876211, Baseline MSE: 1.2679947637193216\nModel saved to saved_models/train_428.pkl\nProcessed train_428.csv, Model MSE: 0.0001258365159061472, Baseline MSE: 1.035571471063816\nModel saved to saved_models/train_200.pkl\nProcessed train_200.csv, Model MSE: 0.007147846308769093, Baseline MSE: 1.0100968779411634\nModel saved to saved_models/train_165.pkl\nProcessed train_165.csv, Model MSE: 0.07125170910445752, Baseline MSE: 1.365052065802292\nModel saved to saved_models/train_212.pkl\nProcessed train_212.csv, Model MSE: 0.0748677899982582, Baseline MSE: 1.0195700900362143\nModel saved to saved_models/train_176.pkl\nProcessed train_176.csv, Model MSE: 0.06710222968891391, Baseline MSE: 1.4576257452178485\nModel saved to saved_models/train_306.pkl\nProcessed train_306.csv, Model MSE: 0.0008482586799779025, Baseline MSE: 1.2379908807043918\nModel saved to saved_models/train_115.pkl\nProcessed train_115.csv, Model MSE: 0.026750612589726053, Baseline MSE: 1.159335397506539\nModel saved to saved_models/train_453.pkl\nProcessed train_453.csv, Model MSE: 7.003616751234504e-06, Baseline MSE: 1.050442314951133\nModel saved to saved_models/train_42.pkl\nProcessed train_42.csv, Model MSE: 0.0020088293706971893, Baseline MSE: 1.0960646153603864\nModel saved to saved_models/train_483.pkl\nProcessed train_483.csv, Model MSE: 0.0006855684554128777, Baseline MSE: 1.1620231067043776\nModel saved to saved_models/train_218.pkl\nProcessed train_218.csv, Model MSE: 0.5109173782871667, Baseline MSE: 1.35957535461405\nModel saved to saved_models/train_256.pkl\nProcessed train_256.csv, Model MSE: 0.03368553315367888, Baseline MSE: 1.4623482529044085\nModel saved to saved_models/train_348.pkl\nProcessed train_348.csv, Model MSE: 0.00988526874986045, Baseline MSE: 1.0223377500939044\nModel saved to saved_models/train_131.pkl\nProcessed train_131.csv, Model MSE: 0.05923742191178165, Baseline MSE: 1.3747882558583489\nModel saved to saved_models/train_301.pkl\nProcessed train_301.csv, Model MSE: 0.07878441684703312, Baseline MSE: 0.8451848159955008\nModel saved to saved_models/train_361.pkl\nProcessed train_361.csv, Model MSE: 0.000987848679909663, Baseline MSE: 1.0283017780649317\nModel saved to saved_models/train_297.pkl\nProcessed train_297.csv, Model MSE: 0.009678342512268654, Baseline MSE: 0.94347462077783\nModel saved to saved_models/train_79.pkl\nProcessed train_79.csv, Model MSE: 0.004430794235323523, Baseline MSE: 1.0053475553152629\nModel saved to saved_models/train_9.pkl\nProcessed train_9.csv, Model MSE: 0.0028960637309407705, Baseline MSE: 1.2480219233657524\nModel saved to saved_models/train_227.pkl\nProcessed train_227.csv, Model MSE: 0.0054711598205423855, Baseline MSE: 1.479420566296982\nModel saved to saved_models/train_242.pkl\nProcessed train_242.csv, Model MSE: 0.016146196655067124, Baseline MSE: 1.0274793310112114\nModel saved to saved_models/train_105.pkl\nProcessed train_105.csv, Model MSE: 0.018432717328646483, Baseline MSE: 1.129161436308961\nModel saved to saved_models/train_391.pkl\nProcessed train_391.csv, Model MSE: 4.548684365726517e-05, Baseline MSE: 0.9320048988421668\nModel saved to saved_models/train_482.pkl\nProcessed train_482.csv, Model MSE: 0.2522007674020242, Baseline MSE: 1.3875624119064915\nModel saved to saved_models/train_118.pkl\nProcessed train_118.csv, Model MSE: 0.0035543080070207047, Baseline MSE: 1.0707079372057597\nModel saved to saved_models/train_440.pkl\nProcessed train_440.csv, Model MSE: 0.01134382934187052, Baseline MSE: 1.3647638283283312\nModel saved to saved_models/train_429.pkl\nProcessed train_429.csv, Model MSE: 0.04416058938712454, Baseline MSE: 1.0948030879939767\nModel saved to saved_models/train_119.pkl\nProcessed train_119.csv, Model MSE: 0.06532902249390028, Baseline MSE: 1.0015738675741845\nModel saved to saved_models/train_310.pkl\nProcessed train_310.csv, Model MSE: 0.01928771406953913, Baseline MSE: 1.287833167868516\nModel saved to saved_models/train_209.pkl\nProcessed train_209.csv, Model MSE: 0.03859241973114793, Baseline MSE: 1.3570853276026373\nModel saved to saved_models/train_185.pkl\nProcessed train_185.csv, Model MSE: 0.09996012739605857, Baseline MSE: 1.5308155082012587\nModel saved to saved_models/train_397.pkl\nProcessed train_397.csv, Model MSE: 0.31760576540628216, Baseline MSE: 1.4390361288039388\nModel saved to saved_models/train_141.pkl\nProcessed train_141.csv, Model MSE: 0.05017622533879482, Baseline MSE: 1.2585954869415474\nModel saved to saved_models/train_447.pkl\nProcessed train_447.csv, Model MSE: 0.014867741782653649, Baseline MSE: 1.394312800285654\nModel saved to saved_models/train_188.pkl\nProcessed train_188.csv, Model MSE: 0.15839088452193142, Baseline MSE: 1.5089675319248306\nModel saved to saved_models/train_198.pkl\nProcessed train_198.csv, Model MSE: 0.11716811368185416, Baseline MSE: 1.3602961426752727\nModel saved to saved_models/train_451.pkl\nProcessed train_451.csv, Model MSE: 0.001643181929720662, Baseline MSE: 1.1568274392536413\nModel saved to saved_models/train_39.pkl\nProcessed train_39.csv, Model MSE: 0.0005952016972358622, Baseline MSE: 1.0940527412225525\nModel saved to saved_models/train_498.pkl\nProcessed train_498.csv, Model MSE: 0.0007267493778248232, Baseline MSE: 1.1340759755094476\nModel saved to saved_models/train_314.pkl\nProcessed train_314.csv, Model MSE: 0.015229621299552762, Baseline MSE: 0.9930686915139914\nModel saved to saved_models/train_437.pkl\nProcessed train_437.csv, Model MSE: 0.00042984245857592837, Baseline MSE: 1.2821357723468767\nModel saved to saved_models/train_66.pkl\nProcessed train_66.csv, Model MSE: 0.016200412674801868, Baseline MSE: 1.0411085384661416\nModel saved to saved_models/train_430.pkl\nProcessed train_430.csv, Model MSE: 0.32160942410401067, Baseline MSE: 1.375571073746362\nModel saved to saved_models/train_461.pkl\nProcessed train_461.csv, Model MSE: 0.004187624329984001, Baseline MSE: 1.1212236095625092\nModel saved to saved_models/train_386.pkl\nProcessed train_386.csv, Model MSE: 2.3843427659030014e-05, Baseline MSE: 1.0944875840944206\nModel saved to saved_models/train_435.pkl\nProcessed train_435.csv, Model MSE: 8.983864555088169e-05, Baseline MSE: 1.2396227944841605\nModel saved to saved_models/train_103.pkl\nProcessed train_103.csv, Model MSE: 0.006594117406019567, Baseline MSE: 1.0311671649985812\nModel saved to saved_models/train_110.pkl\nProcessed train_110.csv, Model MSE: 0.013371831007863603, Baseline MSE: 1.1369755184830674\nModel saved to saved_models/train_325.pkl\nProcessed train_325.csv, Model MSE: 0.00328335596738825, Baseline MSE: 1.0361530443132618\nModel saved to saved_models/train_211.pkl\nProcessed train_211.csv, Model MSE: 0.1272104544215056, Baseline MSE: 1.464105341899622\nModel saved to saved_models/train_401.pkl\nProcessed train_401.csv, Model MSE: 0.014561908144081277, Baseline MSE: 1.4332713134324317\nModel saved to saved_models/train_490.pkl\nProcessed train_490.csv, Model MSE: 0.13310930680797356, Baseline MSE: 1.4586111718124033\nModel saved to saved_models/train_272.pkl\nProcessed train_272.csv, Model MSE: 2.3630719900858543e-05, Baseline MSE: 0.9394835893386005\nModel saved to saved_models/train_287.pkl\nProcessed train_287.csv, Model MSE: 0.005242088217868495, Baseline MSE: 1.362219039746196\nModel saved to saved_models/train_370.pkl\nProcessed train_370.csv, Model MSE: 0.006480217025631235, Baseline MSE: 1.051178967758378\nModel saved to saved_models/train_338.pkl\nProcessed train_338.csv, Model MSE: 0.005152448870580199, Baseline MSE: 1.0715176159154376\nModel saved to saved_models/train_462.pkl\nProcessed train_462.csv, Model MSE: 0.0038411030545390254, Baseline MSE: 1.1127250867638798\nModel saved to saved_models/train_177.pkl\nProcessed train_177.csv, Model MSE: 0.01947078356525008, Baseline MSE: 1.5390127863490624\nModel saved to saved_models/train_367.pkl\nProcessed train_367.csv, Model MSE: 2.888856092047986e-05, Baseline MSE: 1.0072792694338681\nModel saved to saved_models/train_491.pkl\nProcessed train_491.csv, Model MSE: 0.06520282386810929, Baseline MSE: 1.4835290704940327\nModel saved to saved_models/train_153.pkl\nProcessed train_153.csv, Model MSE: 0.09459561603812897, Baseline MSE: 1.5220525749982468\nModel saved to saved_models/train_335.pkl\nProcessed train_335.csv, Model MSE: 5.922163465441238e-05, Baseline MSE: 1.017456154016533\nModel saved to saved_models/train_217.pkl\nProcessed train_217.csv, Model MSE: 0.37903469123227224, Baseline MSE: 1.2878070364836867\nModel saved to saved_models/train_161.pkl\nProcessed train_161.csv, Model MSE: 0.0027865808560071656, Baseline MSE: 1.4374279104018695\nModel saved to saved_models/train_43.pkl\nProcessed train_43.csv, Model MSE: 0.016523026826860042, Baseline MSE: 0.9141470331108794\nModel saved to saved_models/train_294.pkl\nProcessed train_294.csv, Model MSE: 0.0002957019173916334, Baseline MSE: 0.8686684741214663\nModel saved to saved_models/train_12.pkl\nProcessed train_12.csv, Model MSE: 1.901181773922174e-05, Baseline MSE: 1.0358714216527765\nModel saved to saved_models/train_383.pkl\nProcessed train_383.csv, Model MSE: 0.004080157149516069, Baseline MSE: 1.0421999913219628\nModel saved to saved_models/train_21.pkl\nProcessed train_21.csv, Model MSE: 0.06472749793992565, Baseline MSE: 1.2816309305598257\nModel saved to saved_models/train_74.pkl\nProcessed train_74.csv, Model MSE: 6.656993978023531e-05, Baseline MSE: 1.1217840217310393\nModel saved to saved_models/train_205.pkl\nProcessed train_205.csv, Model MSE: 0.03231193075853523, Baseline MSE: 1.4823872177609823\nModel saved to saved_models/train_300.pkl\nProcessed train_300.csv, Model MSE: 0.006487517731036887, Baseline MSE: 1.1679414029108872\nModel saved to saved_models/train_102.pkl\nProcessed train_102.csv, Model MSE: 0.018641397780381742, Baseline MSE: 1.1338903222092398\nModel saved to saved_models/train_290.pkl\nProcessed train_290.csv, Model MSE: 2.389965824291062e-05, Baseline MSE: 0.9775287664090252\nModel saved to saved_models/train_155.pkl\nProcessed train_155.csv, Model MSE: 0.0015874010533337916, Baseline MSE: 1.4570792512358457\nModel saved to saved_models/train_23.pkl\nProcessed train_23.csv, Model MSE: 0.014122461863245067, Baseline MSE: 1.3063865647600938\nModel saved to saved_models/train_151.pkl\nProcessed train_151.csv, Model MSE: 0.0822618460611596, Baseline MSE: 1.5387678762778474\nModel saved to saved_models/train_246.pkl\nProcessed train_246.csv, Model MSE: 0.03297305146727052, Baseline MSE: 1.031147539974533\nModel saved to saved_models/train_469.pkl\nProcessed train_469.csv, Model MSE: 0.3435707011383825, Baseline MSE: 1.4974881640178757\nModel saved to saved_models/train_499.pkl\nProcessed train_499.csv, Model MSE: 0.010793774028776525, Baseline MSE: 1.133592193783187\nModel saved to saved_models/train_495.pkl\nProcessed train_495.csv, Model MSE: 3.594353658696146e-05, Baseline MSE: 1.1505892204701669\nModel saved to saved_models/train_354.pkl\nProcessed train_354.csv, Model MSE: 0.0075523621218568215, Baseline MSE: 1.023911853160721\nModel saved to saved_models/train_421.pkl\nProcessed train_421.csv, Model MSE: 0.11133054919132637, Baseline MSE: 1.2020071920197108\nModel saved to saved_models/train_321.pkl\nProcessed train_321.csv, Model MSE: 3.1947283709175426e-05, Baseline MSE: 1.0057937360756808\nModel saved to saved_models/train_465.pkl\nProcessed train_465.csv, Model MSE: 8.678397276346207e-05, Baseline MSE: 0.9977744492334374\nModel saved to saved_models/train_92.pkl\nProcessed train_92.csv, Model MSE: 0.03733100775814725, Baseline MSE: 1.1811928067107995\nModel saved to saved_models/train_75.pkl\nProcessed train_75.csv, Model MSE: 0.0031245636423346468, Baseline MSE: 1.0822457153450513\nModel saved to saved_models/train_505.pkl\nProcessed train_505.csv, Model MSE: 0.007080003087262099, Baseline MSE: 1.0177540277592598\nModel saved to saved_models/train_439.pkl\nProcessed train_439.csv, Model MSE: 0.2583219106722339, Baseline MSE: 1.4766819139791412\nModel saved to saved_models/train_204.pkl\nProcessed train_204.csv, Model MSE: 0.12856365224179048, Baseline MSE: 1.3742836726772918\nModel saved to saved_models/train_251.pkl\nProcessed train_251.csv, Model MSE: 0.164712809803274, Baseline MSE: 1.1206086574009653\nModel saved to saved_models/train_507.pkl\nProcessed train_507.csv, Model MSE: 4.727888037167999e-05, Baseline MSE: 1.0017452383661234\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Comments\n\n1. **Low MSE Values Indicating Good Model Performance**: \n   - Several models have very low MSE values compared to their baselines, which suggests that they have learned well and can predict the target variable accurately. For instance:\n     - `train_453.csv`: Model MSE = 0.000007, Baseline MSE = 1.050442\n     - `train_391.csv`: Model MSE = 0.000045, Baseline MSE = 0.932005\n     - `train_495.csv`: Model MSE = 0.000035, Baseline MSE = 1.150589\n   \n   These models outperform the baseline significantly, meaning they are capturing relationships in the data effectively.\n\n2. **High MSE Values Indicating Poorer Model Performance**:\n   - Some models, while still performing better than the baseline, have higher MSEs, which suggests they may not be fitting the data as well or there may be room for improvement in the model or feature engineering:\n     - `train_218.csv`: Model MSE = 0.510917, Baseline MSE = 1.359575\n     - `train_211.csv`: Model MSE = 0.127210, Baseline MSE = 1.464105\n\n   These models show some predictive ability, but their MSEs indicate they are less accurate compared to others.\n\n3. **Anomalous or Poor Results**:\n   - Some models have MSE values that are still relatively high or are worse than other models:\n     - `train_491.csv`: Model MSE = 0.065203, Baseline MSE = 1.483529\n     - `train_204.csv`: Model MSE = 0.128564, Baseline MSE = 1.374284\n\n   These models are not capturing the data relationships as effectively as others and might benefit from further tuning, feature selection, or a change in model architecture.\n\n4. **Models with Very Small MSEs**: \n   - Some models have extremely low MSE values (e.g., `train_505.csv`: MSE = 0.007080), indicating they are very close to perfect predictions. While these are generally positive results, extremely low MSEs can also sometimes indicate potential overfitting, especially if the baseline MSE is still relatively large.\n\n5. **Overall Performance**: \n   - Generally, the models outperform their baselines, which is a positive indication of successful training. However, there is considerable variation in the performance across different datasets (MSE ranging from very small values to higher ones like 0.510917 or 0.128564), suggesting that some datasets may be easier to predict or may benefit from more fine-tuning than others.\n\n### Suggestions for Improvement:\n- **Hyperparameter Tuning**: For models with higher MSE values, I should try tuning the model parameters (e.g., learning rate, number of layers) to improve performance.\n- **Feature Engineering**: I should consider exploring feature engineering techniques like normalization, scaling, or creating new features for better results on datasets with higher MSEs.\n- **Cross-Validation**: I should implement cross-validation to better evaluate model generalization across different parts of the dataset and avoid overfitting on smaller datasets.","metadata":{}}]}
